#ifndef NEURAL_NODES_H
#define NEURAL_NODES_H


#include "neuralNet.h"


inline const char* im2col_srcCode = R"(
#version 450
layout(local_size_x = 64, local_size_y = 16) in;
layout(set = 0, binding = 0) writeonly buffer OutBuffer { float im2colOut[]; };
layout(set = 0, binding = 1) readonly buffer InBuffer { float in0[]; };
layout(push_constant) uniform PushConstants {
    int H;
    int W;
    int C;
    int K;
};

void main() 
{
    int i = int(gl_GlobalInvocationID.x); 
    int j = int(gl_GlobalInvocationID.y); 
    int KK = K * K;
    int CKK = C * KK;
    if (i >= H * W || j >= CKK) 
        return;

    int h = i / W;          // image center row
    int w = i % W;          // image center col
    int c = j / KK;         // image channel
    int K_2 = K / 2;
    int k = j % KK;

    float value = 0.0;
    h += k / K - K_2;  
    w += k % K - K_2;   
    if (0 <= h && h < H && 0 <= w && w < W) 
        value = in0[((h * W) + w) * C + c];

    im2colOut[i * CKK + j] = value;
})";

inline const char* gemm_srcCode = R"(
#version 450
layout(local_size_x = 64, local_size_y = 16) in;
layout(set = 0, binding = 0) buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) buffer InBuffer { float in0[]; };
layout(set = 0, binding = 2) buffer Weight { float weight[]; };
layout(set = 0, binding = 3) buffer Bias { float bias[]; };

// out0(NxO) = in0(NxI) * weight(IxO) + bias(O)
layout(push_constant) uniform PushConstants {
    int N;
    int I;
    int O;
};

void main() 
{
    int n = int(gl_GlobalInvocationID.x); 
    int o = int(gl_GlobalInvocationID.y); 
    if (n >= N || o >= O) 
        return;

    float sum = bias[o];
    for (int i = 0; i < I; ++i)
        sum += in0[n * I + i] * weight[i * O + o];

    out0[n * O + o] = sum;
})";

inline const char* relu_srcCode = R"(
#version 450
layout(local_size_x = 64) in;
layout(set = 0, binding = 0) buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) buffer InBuffer { float in0[]; };
layout(push_constant) uniform PushConstants {
    int I;
};

void main() 
{
    int i = int(gl_GlobalInvocationID.x);
    if (i >= I) 
        return;

    out0[i] = max(in0[i], 0.0f);
})";

inline const char* copy_srcCode = R"(
#version 450
layout(local_size_x = 64) in;
layout(set = 0, binding = 0) buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) buffer InBuffer { float in0[]; };
layout(push_constant) uniform PushConstants {
    int I;
};

void main() 
{
    int i = int(gl_GlobalInvocationID.x);
    if (i >= I) 
        return;

    out0[i] = in0[i];
})";

inline const char* maxpool_srcCode = R"(
#version 450
#define FLT_MIN -3.402823466e+38
#define DISCARD_TAIL
layout(local_size_x = 64, local_size_y = 4, local_size_z = 4) in;
layout(set = 0, binding = 0) buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) buffer InBuffer { float in0[]; };
layout(push_constant) uniform PushConstants {
    int H;      // input height
    int W;      // input width
    int C;
    int P;      // pooling size
};

void main()
{
    int h_ = int(gl_GlobalInvocationID.x);  // output row
    int w_ = int(gl_GlobalInvocationID.y);  // output col
    int c = int(gl_GlobalInvocationID.z);   // channel
#ifdef DISCARD_TAIL
    int H_ = H / P;  
    int W_ = W / P;  
#else
    int H_ = (H + P - 1) / P;
    int W_ = (W + P - 1) / P;
#endif
    if (h_ >= H_ || w_ >= W_ || c >= C)
        return;

    int h0 = h_ * P;  
    int w0 = w_ * P;     
    float maxVal = FLT_MIN;
    for (int dh=0; dh < P; ++dh) 
    {
        int h = h0 + dh;  
        for (int dw=0; dw < P; ++dw) 
        {
            int w = w0 + dw;

        #ifndef DISCARD_TAIL
            if (h < H && w < W) 
        #endif
            {
                maxVal = max(maxVal, in0[(h * W + w) * C + c]);
            }
        }
    }
    out0[(h_ * W_ + w_) * C + c] = maxVal;
})";

inline const char* relu6_srcCode = R"(
#version 450
layout(local_size_x = 256) in;
layout(set = 0, binding = 0) buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) buffer InBuffer { float in0[]; };
layout(push_constant) uniform PushConstants {
    int N;
};
void main() 
{
    int i = int(gl_GlobalInvocationID.x);
    if (i >= N) return;
    out0[i] = clamp(in0[i], 0.0, 6.0);
})";
// Element-wise Add
inline const char* add_srcCode = R"(
#version 450
layout(local_size_x = 256) in;
layout(set = 0, binding = 0) buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) buffer InBuffer0 { float in0[]; };
layout(set = 0, binding = 2) buffer InBuffer1 { float in1[]; };
layout(push_constant) uniform PushConstants {
    int N;
};
void main() 
{
    int i = int(gl_GlobalInvocationID.x);
    if (i >= N) return;
    out0[i] = in0[i] + in1[i];
})";
// BatchNorm (inference mode): y = gamma * (x - mean) / sqrt(var + eps) + beta
inline const char* batchnorm_srcCode = R"(
#version 450
layout(local_size_x = 256) in;
layout(set = 0, binding = 0) buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) buffer InBuffer { float in0[]; };
layout(set = 0, binding = 2) buffer Gamma { float gamma[]; };
layout(set = 0, binding = 3) buffer Beta { float beta[]; };
layout(set = 0, binding = 4) buffer Mean { float running_mean[]; };
layout(set = 0, binding = 5) buffer Var { float running_var[]; };
layout(push_constant) uniform PushConstants {
    int HW;  // H * W
    int C;
    float eps;
};
void main() 
{
    int i = int(gl_GlobalInvocationID.x);
    int total = HW * C;
    if (i >= total) return;
    int c = i % C;  // channel index (HWC layout)
    float x = in0[i];
    float mean = running_mean[c];
    float var = running_var[c];
    float g = gamma[c];
    float b = beta[c];
    out0[i] = g * (x - mean) * inversesqrt(var + eps) + b;
})";
// Global Average Pooling: [H][W][C] -> [C]
inline const char* gap_srcCode = R"(
#version 450
layout(local_size_x = 64) in;
layout(set = 0, binding = 0) buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) buffer InBuffer { float in0[]; };
layout(push_constant) uniform PushConstants {
    int H, W, C;
};
void main() 
{
    int c = int(gl_GlobalInvocationID.x);
    if (c >= C) return;
    float sum = 0.0;
    int HW = H * W;
    for (int i = 0; i < HW; ++i) {
        sum += in0[i * C + c];
    }
    out0[c] = sum / float(HW);
})";
// Depthwise Convolution with stride and padding
inline const char* dwconv_srcCode = R"(
#version 450
layout(local_size_x = 8, local_size_y = 8, local_size_z = 4) in;
layout(set = 0, binding = 0) writeonly buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) readonly buffer InBuffer { float in0[]; };
layout(set = 0, binding = 2) readonly buffer Weight { float weight[]; };
layout(push_constant) uniform PushConstants {
    int H_in, W_in, C;
    int H_out, W_out;
    int K, stride, pad;
};
void main() 
{
    int h_out = int(gl_GlobalInvocationID.x);
    int w_out = int(gl_GlobalInvocationID.y);
    int c = int(gl_GlobalInvocationID.z);
    if (h_out >= H_out || w_out >= W_out || c >= C)
        return;
    float sum = 0.0;
    int h_start = h_out * stride - pad;
    int w_start = w_out * stride - pad;
    for (int kh = 0; kh < K; ++kh) {
        int h_in = h_start + kh;
        if (h_in < 0 || h_in >= H_in) continue;
        for (int kw = 0; kw < K; ++kw) {
            int w_in = w_start + kw;
            if (w_in < 0 || w_in >= W_in) continue;
            float val = in0[(h_in * W_in + w_in) * C + c];
            float wgt = weight[(kh * K + kw) * C + c];  // weight layout: [K][K][C]
            sum += val * wgt;
        }
    }
    out0[(h_out * W_out + w_out) * C + c] = sum;
})";
// Pointwise (1x1) Convolution
inline const char* pwconv_srcCode = R"(
#version 450
layout(local_size_x = 8, local_size_y = 8, local_size_z = 4) in;
layout(set = 0, binding = 0) writeonly buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) readonly buffer InBuffer { float in0[]; };
layout(set = 0, binding = 2) readonly buffer Weight { float weight[]; };
layout(push_constant) uniform PushConstants {
    int H, W;
    int C_in, C_out;
};
void main() 
{
    int h = int(gl_GlobalInvocationID.x);
    int w = int(gl_GlobalInvocationID.y);
    int c_out = int(gl_GlobalInvocationID.z);
    if (h >= H || w >= W || c_out >= C_out)
        return;
    float sum = 0.0;
    int hw_offset = (h * W + w) * C_in;
    for (int c_in = 0; c_in < C_in; ++c_in) {
        sum += in0[hw_offset + c_in] * weight[c_in * C_out + c_out];
    }
    out0[(h * W + w) * C_out + c_out] = sum;
})";
// Standard Convolution with stride (for first layer)
inline const char* conv_stride_srcCode = R"(
#version 450
layout(local_size_x = 8, local_size_y = 8, local_size_z = 4) in;
layout(set = 0, binding = 0) writeonly buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) readonly buffer InBuffer { float in0[]; };
layout(set = 0, binding = 2) readonly buffer Weight { float weight[]; };
layout(set = 0, binding = 3) readonly buffer Bias { float bias[]; };
layout(push_constant) uniform PushConstants {
    int H_in, W_in, C_in;
    int H_out, W_out, C_out;
    int K, stride, pad;
};
void main() 
{
    int h_out = int(gl_GlobalInvocationID.x);
    int w_out = int(gl_GlobalInvocationID.y);
    int c_out = int(gl_GlobalInvocationID.z);
    if (h_out >= H_out || w_out >= W_out || c_out >= C_out)
        return;
    float sum = bias[c_out];
    int h_start = h_out * stride - pad;
    int w_start = w_out * stride - pad;
    for (int kh = 0; kh < K; ++kh) {
        int h_in = h_start + kh;
        if (h_in < 0 || h_in >= H_in) continue;
        for (int kw = 0; kw < K; ++kw) {
            int w_in = w_start + kw;
            if (w_in < 0 || w_in >= W_in) continue;
            for (int c_in = 0; c_in < C_in; ++c_in) {
                float val = in0[(h_in * W_in + w_in) * C_in + c_in];
                int w_idx = ((c_out * C_in + c_in) * K + kh) * K + kw;
                sum += val * weight[w_idx];
            }
        }
    }
    out0[(h_out * W_out + w_out) * C_out + c_out] = sum;
})";

inline const char* fully_connected_srcCode = R"(
#version 450
layout(local_size_x = 64, local_size_y = 16) in;
layout(set = 0, binding = 0) buffer OutBuffer { float out0[]; };
layout(set = 0, binding = 1) buffer InBuffer { float in0[]; };
layout(set = 0, binding = 2) buffer Weight { float weight[]; };
layout(set = 0, binding = 3) buffer Bias { float bias[]; };
layout(push_constant) uniform PushConstants {
    int N;  // batch size (1 for now)
    int I;  // input features
    int O;  // output features
};
void main() 
{
    int n = int(gl_GlobalInvocationID.x); 
    int o = int(gl_GlobalInvocationID.y); 
    if (n >= N || o >= O) 
        return;
    float sum = bias[o];
    for (int i = 0; i < I; ++i)
        sum += in0[n * I + i] * weight[i * O + o];
    out0[n * O + o] = sum;
})";

inline static Device gDevice = VulkanApp::get().createDevice({.supportPresent = false});
inline static DescriptorPool gDestSetPool = gDevice.createDescriptorPool({
    .maxTypes = {VK_DESCRIPTOR_TYPE_STORAGE_BUFFER <= 10000}, 
    .maxSets = 5000
});

class ConvolutionNode : public Node
{
    uint32_t C, F, K;   // C: input channels, F: output channels, K: kernel width

    ComputePipeline im2col;
    ComputePipeline gemm;
    DescriptorSet im2colDescSet;
    DescriptorSet gemmDescSet;

public:
    ConvolutionNode(uint32_t inChannels, uint32_t outChannels, uint32_t kernelWidth)
    :  C(inChannels), F(outChannels), K(kernelWidth)
    {
        _ASSERT(K % 2 == 1);
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        addSlot("im2colOut", NodeSlot::internal);
        addSlot("weight", NodeSlot::input);
        addSlot("bias", NodeSlot::input); 

        im2col = gDevice.createComputePipeline({im2col_srcCode});
        gemm = gDevice.createComputePipeline({gemm_srcCode});
        im2colDescSet = im2col.descSetLayout(0).newDescSet(gDestSetPool);
        gemmDescSet = gemm.descSetLayout(0).newDescSet(gDestSetPool);
    }

    void prepare() override
    {
        _ASSERT((*this)["in0"].isShapeOf(-1, -1, C));
        _ASSERT((*this)["weight"].isShapeOf(C*K*K, F));
        _ASSERT((*this)["bias"].isShapeOf(F));

        const auto& inShape = (*this)["in0"].shape();
        (*this)["im2colOut"] = Tensor(inShape[0], inShape[1], C*K*K);
        (*this)["out0"] = Tensor(inShape[0], inShape[1], F);
    }
    
    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        uint32_t H = inShape[0], W = inShape[1];

        im2colDescSet.write({
            (*this)["im2colOut"].buffer(),
            (*this)["in0"].buffer(),
        });

        gemmDescSet.write({
            (*this)["out0"].buffer(),
            (*this)["im2colOut"].buffer(),
            (*this)["weight"].buffer(),
            (*this)["bias"].buffer(),
        });

        uint32_t im2colConstants[] = {H, W, C, K};
        uint32_t gemmConstants[] = {H * W, C * K * K, F};

        cmdBuff
            .bindPipeline(im2col)
            .bindDescSets({im2colDescSet})
            .setPushConstants(0, sizeof(im2colConstants), im2colConstants)
            .dispatch(H * W, C * K * K)
            .barrier( 
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["im2colOut"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            )

            .bindPipeline(gemm)
            .bindDescSets({gemmDescSet})
            .setPushConstants(0, sizeof(gemmConstants), gemmConstants)
            .dispatch(H * W, F)
            .barrier( 
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }  
};


class ReluNode : public Node
{
    ComputePipeline relu;
    DescriptorSet reluDescSet;

public:
    ReluNode()
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);

        relu = gDevice.createComputePipeline({relu_srcCode});
        reluDescSet = relu.descSetLayout(0).newDescSet(gDestSetPool);
    }

    void prepare() override
    {
        _ASSERT((*this)["in0"].validShape());
        (*this)["out0"] = Tensor((*this)["in0"].shape());
    }
    
    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        int I = 1;
        for (int dim : inShape) I *= dim;
        
        reluDescSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
        });

        int reluConstants[] = {I};

        cmdBuff
            .bindPipeline(relu)
            .setPushConstants(0, sizeof(reluConstants), reluConstants)
            .bindDescSets({reluDescSet})
            .dispatch(I)
            .barrier( 
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }  
};


class MaxPoolingNode : public Node
{
    const bool discardTail = true; // If true, discard the tail elements that don't fit into the pooling window
    uint32_t P;

    ComputePipeline maxpool;
    DescriptorSet maxpoolDescSet;

public:
    MaxPoolingNode(uint32_t poolSize)
    : P(poolSize)
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);

        maxpool = gDevice.createComputePipeline({maxpool_srcCode});
        maxpoolDescSet = maxpool.descSetLayout(0).newDescSet(gDestSetPool);
    }

    void prepare() override
    {
        const auto& inShape = (*this)["in0"].shape();
        _ASSERT(inShape.size() == 3);
        uint32_t H = inShape[0], W = inShape[1], C = inShape[2];

        if (discardTail)
            (*this)["out0"] = Tensor(H / P, W / P, C);
        else    
            (*this)["out0"] = Tensor((H + P - 1) / P, (W + P - 1) / P, C);

    }

    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        uint32_t H = inShape[0], W = inShape[1], C = inShape[2];
        uint32_t H_ = discardTail ? H / P : (H + P - 1) / P;
        uint32_t W_ = discardTail ? W / P : (W + P - 1) / P;

        maxpoolDescSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
        });

        uint32_t maxpoolConstants[] = {H, W, C, P};

        cmdBuff
            .bindPipeline(maxpool)
            .bindDescSets({maxpoolDescSet})
            .setPushConstants(0, sizeof(maxpoolConstants), maxpoolConstants)
            .dispatch(H_, W_, C)
            .barrier( 
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }  
};


class FlattenNode : public Node
{
    ComputePipeline copy;
    DescriptorSet copyDescSet;

public:
    FlattenNode()
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);

        copy = gDevice.createComputePipeline({copy_srcCode});
        copyDescSet = copy.descSetLayout(0).newDescSet(gDestSetPool);
    }

    void prepare() override
    {
        _ASSERT((*this)["in0"].validShape());
        (*this)["out0"] = Tensor((*this)["in0"].numElements());
    }

    void run(CommandBuffer cmdBuff) override
    {
        // cmdBuff
        //     .barrier(
        //         (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
        //         / (*this)["in0"].buffer()
        //         / (PIPELINE_STAGE::TRANSFER, ACCESS::TRANSFER_READ)
        //     )
        //     .copyBuffer((*this)["out0"].buffer(), (*this)["in0"].buffer())
        //     .barrier(
        //         (PIPELINE_STAGE::TRANSFER, ACCESS::TRANSFER_WRITE)
        //         / (*this)["out0"].buffer()
        //         / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
        //     );

        const auto& inShape = (*this)["in0"].shape();
        int I = 1;
        for (int dim : inShape) I *= dim;
        
        copyDescSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
        });

        int copyConstants[] = {I};

        cmdBuff
            .bindPipeline(copy)
            .setPushConstants(0, sizeof(copyConstants), copyConstants)
            .bindDescSets({copyDescSet})
            .dispatch(I)
            .barrier( 
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }  
};


// ============================================================================
// Node Implementations
// ============================================================================
class Relu6Node : public Node
{
    ComputePipeline pipeline;
    DescriptorSet descSet;
public:
    Relu6Node()
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        pipeline = gDevice.createComputePipeline({ relu6_srcCode });
        descSet = pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        _ASSERT((*this)["in0"].validShape());
        (*this)["out0"] = Tensor((*this)["in0"].shape());
    }
    void run(CommandBuffer cmdBuff) override
    {
        int N = (*this)["in0"].numElements();
        descSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
            });
        cmdBuff
            .bindPipeline(pipeline)
            .bindDescSets({ descSet })
            .setPushConstants(0, sizeof(N), &N)
            .dispatch(N)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};


class AddNode : public Node
{
    ComputePipeline pipeline;
    DescriptorSet descSet;
public:
    AddNode()
    {
        addSlot("in0", NodeSlot::input);
        addSlot("in1", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        pipeline = gDevice.createComputePipeline({ add_srcCode });
        descSet = pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        _ASSERT((*this)["in0"].validShape());
        (*this)["out0"] = Tensor((*this)["in0"].shape());
    }
    void run(CommandBuffer cmdBuff) override
    {
        int N = (*this)["in0"].numElements();
        descSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
            (*this)["in1"].buffer(),
            });
        cmdBuff
            .bindPipeline(pipeline)
            .bindDescSets({ descSet })
            .setPushConstants(0, sizeof(N), &N)
            .dispatch(N)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};


class BatchNormNode : public Node
{
    uint32_t C;
    float eps;
    ComputePipeline pipeline;
    DescriptorSet descSet;
public:
    BatchNormNode(uint32_t channels, float epsilon = 1e-5f)
        : C(channels), eps(epsilon)
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        addSlot("gamma", NodeSlot::input);
        addSlot("beta", NodeSlot::input);
        addSlot("running_mean", NodeSlot::input);
        addSlot("running_var", NodeSlot::input);
        pipeline = gDevice.createComputePipeline({ batchnorm_srcCode });
        descSet = pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        _ASSERT((*this)["in0"].validShape());
        _ASSERT((*this)["gamma"].isShapeOf(C));
        _ASSERT((*this)["beta"].isShapeOf(C));
        _ASSERT((*this)["running_mean"].isShapeOf(C));
        _ASSERT((*this)["running_var"].isShapeOf(C));
        (*this)["out0"] = Tensor((*this)["in0"].shape());
    }
    void run(CommandBuffer cmdBuff) override
    {
        const auto& shape = (*this)["in0"].shape();
        int HW = 1;
        for (size_t i = 0; i < shape.size() - 1; ++i)
            HW *= shape[i];
        descSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
            (*this)["gamma"].buffer(),
            (*this)["beta"].buffer(),
            (*this)["running_mean"].buffer(),
            (*this)["running_var"].buffer(),
            });
        struct { int HW, C; float eps; } constants = { HW, (int)C, eps };
        cmdBuff
            .bindPipeline(pipeline)
            .bindDescSets({ descSet })
            .setPushConstants(0, sizeof(constants), &constants)
            .dispatch(HW * C)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};


class GlobalAvgPoolNode : public Node
{
    ComputePipeline pipeline;
    DescriptorSet descSet;
public:
    GlobalAvgPoolNode()
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        pipeline = gDevice.createComputePipeline({ gap_srcCode });
        descSet = pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        const auto& shape = (*this)["in0"].shape();
        _ASSERT(shape.size() == 3);
        (*this)["out0"] = Tensor(shape[2]);  // [C]
    }
    void run(CommandBuffer cmdBuff) override
    {
        const auto& shape = (*this)["in0"].shape();
        uint32_t H = shape[0], W = shape[1], C = shape[2];
        descSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
            });
        uint32_t constants[] = { H, W, C };
        cmdBuff
            .bindPipeline(pipeline)
            .bindDescSets({ descSet })
            .setPushConstants(0, sizeof(constants), constants)
            .dispatch(C)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};


class DepthwiseConvNode : public Node
{
    uint32_t C, K, stride, pad;
    ComputePipeline pipeline;
    DescriptorSet descSet;
public:
    DepthwiseConvNode(uint32_t channels, uint32_t kernelSize = 3,
        uint32_t stride = 1, uint32_t padding = 1)
        : C(channels), K(kernelSize), stride(stride), pad(padding)
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        addSlot("weight", NodeSlot::input);
        pipeline = gDevice.createComputePipeline({ dwconv_srcCode });
        descSet = pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        const auto& inShape = (*this)["in0"].shape();
        _ASSERT(inShape.size() == 3);
        _ASSERT(inShape[2] == C);
        _ASSERT((*this)["weight"].isShapeOf(K * K, C));
        uint32_t H_in = inShape[0], W_in = inShape[1];
        uint32_t H_out = (H_in + 2 * pad - K) / stride + 1;
        uint32_t W_out = (W_in + 2 * pad - K) / stride + 1;
        (*this)["out0"] = Tensor(H_out, W_out, C);
    }
    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        const auto& outShape = (*this)["out0"].shape();
        descSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
            (*this)["weight"].buffer(),
            });
        struct {
            int H_in, W_in, C;
            int H_out, W_out;
            int K, stride, pad;
        } constants = {
            (int)inShape[0], (int)inShape[1], (int)C,
            (int)outShape[0], (int)outShape[1],
            (int)K, (int)stride, (int)pad
        };
        cmdBuff
            .bindPipeline(pipeline)
            .bindDescSets({ descSet })
            .setPushConstants(0, sizeof(constants), &constants)
            .dispatch(outShape[0], outShape[1], C)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};


class PointwiseConvNode : public Node
{
    uint32_t C_in, C_out;
    ComputePipeline pipeline;
    DescriptorSet descSet;
public:
    PointwiseConvNode(uint32_t inChannels, uint32_t outChannels)
        : C_in(inChannels), C_out(outChannels)
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        addSlot("weight", NodeSlot::input);
        pipeline = gDevice.createComputePipeline({ pwconv_srcCode });
        descSet = pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        const auto& inShape = (*this)["in0"].shape();
        _ASSERT(inShape.size() == 3);
        _ASSERT(inShape[2] == C_in);
        _ASSERT((*this)["weight"].isShapeOf(C_in, C_out));
        (*this)["out0"] = Tensor(inShape[0], inShape[1], C_out);
    }
    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        uint32_t H = inShape[0], W = inShape[1];
        descSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
            (*this)["weight"].buffer(),
            });
        uint32_t constants[] = { H, W, C_in, C_out };
        cmdBuff
            .bindPipeline(pipeline)
            .bindDescSets({ descSet })
            .setPushConstants(0, sizeof(constants), constants)
            .dispatch(H, W, C_out)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};


class FullyConnectedNode : public Node
{
    uint32_t I, O;
    ComputePipeline pipeline;
    DescriptorSet descSet;
public:
    FullyConnectedNode(uint32_t inFeatures, uint32_t outFeatures)
        : I(inFeatures), O(outFeatures)
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        addSlot("weight", NodeSlot::input);
        addSlot("bias", NodeSlot::input);
        pipeline = gDevice.createComputePipeline({ fully_connected_srcCode });
        descSet = pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        _ASSERT((*this)["in0"].isShapeOf(I));
        _ASSERT((*this)["weight"].isShapeOf(I, O));
        _ASSERT((*this)["bias"].isShapeOf(O));
        (*this)["out0"] = Tensor(O);
    }
    void run(CommandBuffer cmdBuff) override
    {
        descSet.write({
            (*this)["out0"].buffer(),
            (*this)["in0"].buffer(),
            (*this)["weight"].buffer(),
            (*this)["bias"].buffer(),
            });
        uint32_t constants[] = { 1, I, O };
        cmdBuff
            .bindPipeline(pipeline)
            .bindDescSets({ descSet })
            .setPushConstants(0, sizeof(constants), constants)
            .dispatch(1, O)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};


// ============================================================================
// Node Groups
// ============================================================================

// Conv + BatchNorm + ReLU6 combined node (for first layer)
class ConvBnRelu6Node : public Node
{
    uint32_t C_in, C_out, K, stride, pad;
    float eps;
    ComputePipeline convPipeline;
    ComputePipeline bnPipeline;
    ComputePipeline relu6Pipeline;
    DescriptorSet convDescSet;
    DescriptorSet bnDescSet;
    DescriptorSet relu6DescSet;
public:
    ConvBnRelu6Node(uint32_t inChannels, uint32_t outChannels,
        uint32_t kernelSize = 3, uint32_t stride = 1, uint32_t padding = 1,
        float epsilon = 1e-5f)
        : C_in(inChannels), C_out(outChannels), K(kernelSize), stride(stride), pad(padding), eps(epsilon)
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        addSlot("conv_out", NodeSlot::internal);
        addSlot("bn_out", NodeSlot::internal);
        addSlot("conv_weight", NodeSlot::input);
        addSlot("conv_bias", NodeSlot::input);
        addSlot("bn_gamma", NodeSlot::input);
        addSlot("bn_beta", NodeSlot::input);
        addSlot("bn_mean", NodeSlot::input);
        addSlot("bn_var", NodeSlot::input);
        convPipeline = gDevice.createComputePipeline({ conv_stride_srcCode });
        bnPipeline = gDevice.createComputePipeline({ batchnorm_srcCode });
        relu6Pipeline = gDevice.createComputePipeline({ relu6_srcCode });
        convDescSet = convPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        bnDescSet = bnPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        relu6DescSet = relu6Pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        const auto& inShape = (*this)["in0"].shape();
        _ASSERT(inShape.size() == 3);
        _ASSERT(inShape[2] == C_in);
        uint32_t H_in = inShape[0], W_in = inShape[1];
        uint32_t H_out = (H_in + 2 * pad - K) / stride + 1;
        uint32_t W_out = (W_in + 2 * pad - K) / stride + 1;
        (*this)["conv_out"] = Tensor(H_out, W_out, C_out);
        (*this)["bn_out"] = Tensor(H_out, W_out, C_out);
        (*this)["out0"] = Tensor(H_out, W_out, C_out);
    }
    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        const auto& outShape = (*this)["out0"].shape();
        uint32_t H_in = inShape[0], W_in = inShape[1];
        uint32_t H_out = outShape[0], W_out = outShape[1];
        // Conv
        convDescSet.write({
            (*this)["conv_out"].buffer(),
            (*this)["in0"].buffer(),
            (*this)["conv_weight"].buffer(),
            (*this)["conv_bias"].buffer(),
            });
        struct {
            int H_in, W_in, C_in;
            int H_out, W_out, C_out;
            int K, stride, pad;
        } convConstants = {
            (int)H_in, (int)W_in, (int)C_in,
            (int)H_out, (int)W_out, (int)C_out,
            (int)K, (int)stride, (int)pad
        };
        cmdBuff
            .bindPipeline(convPipeline)
            .bindDescSets({ convDescSet })
            .setPushConstants(0, sizeof(convConstants), &convConstants)
            .dispatch(H_out, W_out, C_out)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["conv_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
        // BatchNorm
        bnDescSet.write({
            (*this)["bn_out"].buffer(),
            (*this)["conv_out"].buffer(),
            (*this)["bn_gamma"].buffer(),
            (*this)["bn_beta"].buffer(),
            (*this)["bn_mean"].buffer(),
            (*this)["bn_var"].buffer(),
            });
        struct { int HW, C; float eps; } bnConstants = { (int)(H_out * W_out), (int)C_out, eps };
        cmdBuff
            .bindPipeline(bnPipeline)
            .bindDescSets({ bnDescSet })
            .setPushConstants(0, sizeof(bnConstants), &bnConstants)
            .dispatch(H_out * W_out * C_out)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["bn_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
        // ReLU6
        int N = H_out * W_out * C_out;
        relu6DescSet.write({
            (*this)["out0"].buffer(),
            (*this)["bn_out"].buffer(),
            });
        cmdBuff
            .bindPipeline(relu6Pipeline)
            .bindDescSets({ relu6DescSet })
            .setPushConstants(0, sizeof(N), &N)
            .dispatch(N)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};

// Depthwise Conv + BatchNorm + ReLU6 combined node
class DwConvBnRelu6Node : public Node
{
    uint32_t C, K, stride, pad;
    float eps;
    ComputePipeline dwconvPipeline;
    ComputePipeline bnPipeline;
    ComputePipeline relu6Pipeline;
    DescriptorSet dwconvDescSet;
    DescriptorSet bnDescSet;
    DescriptorSet relu6DescSet;
public:
    DwConvBnRelu6Node(uint32_t channels, uint32_t kernelSize = 3,
        uint32_t stride = 1, uint32_t padding = 1, float epsilon = 1e-5f)
        : C(channels), K(kernelSize), stride(stride), pad(padding), eps(epsilon)
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        addSlot("dw_out", NodeSlot::internal);
        addSlot("bn_out", NodeSlot::internal);
        addSlot("dw_weight", NodeSlot::input);
        addSlot("bn_gamma", NodeSlot::input);
        addSlot("bn_beta", NodeSlot::input);
        addSlot("bn_mean", NodeSlot::input);
        addSlot("bn_var", NodeSlot::input);
        dwconvPipeline = gDevice.createComputePipeline({ dwconv_srcCode });
        bnPipeline = gDevice.createComputePipeline({ batchnorm_srcCode });
        relu6Pipeline = gDevice.createComputePipeline({ relu6_srcCode });
        dwconvDescSet = dwconvPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        bnDescSet = bnPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        relu6DescSet = relu6Pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        const auto& inShape = (*this)["in0"].shape();
        _ASSERT(inShape.size() == 3);
        _ASSERT(inShape[2] == C);
        uint32_t H_in = inShape[0], W_in = inShape[1];
        uint32_t H_out = (H_in + 2 * pad - K) / stride + 1;
        uint32_t W_out = (W_in + 2 * pad - K) / stride + 1;
        (*this)["dw_out"] = Tensor(H_out, W_out, C);
        (*this)["bn_out"] = Tensor(H_out, W_out, C);
        (*this)["out0"] = Tensor(H_out, W_out, C);
    }
    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        const auto& outShape = (*this)["out0"].shape();
        uint32_t H_in = inShape[0], W_in = inShape[1];
        uint32_t H_out = outShape[0], W_out = outShape[1];
        // Depthwise Conv
        dwconvDescSet.write({
            (*this)["dw_out"].buffer(),
            (*this)["in0"].buffer(),
            (*this)["dw_weight"].buffer(),
            });
        struct {
            int H_in, W_in, C;
            int H_out, W_out;
            int K, stride, pad;
        } dwConstants = {
            (int)H_in, (int)W_in, (int)C,
            (int)H_out, (int)W_out,
            (int)K, (int)stride, (int)pad
        };
        cmdBuff
            .bindPipeline(dwconvPipeline)
            .bindDescSets({ dwconvDescSet })
            .setPushConstants(0, sizeof(dwConstants), &dwConstants)
            .dispatch(H_out, W_out, C)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["dw_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
        // BatchNorm
        bnDescSet.write({
            (*this)["bn_out"].buffer(),
            (*this)["dw_out"].buffer(),
            (*this)["bn_gamma"].buffer(),
            (*this)["bn_beta"].buffer(),
            (*this)["bn_mean"].buffer(),
            (*this)["bn_var"].buffer(),
            });
        struct { int HW, C; float eps; } bnConstants = { (int)(H_out * W_out), (int)C, eps };
        cmdBuff
            .bindPipeline(bnPipeline)
            .bindDescSets({ bnDescSet })
            .setPushConstants(0, sizeof(bnConstants), &bnConstants)
            .dispatch(H_out * W_out * C)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["bn_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
        // ReLU6
        int N = H_out * W_out * C;
        relu6DescSet.write({
            (*this)["out0"].buffer(),
            (*this)["bn_out"].buffer(),
            });
        cmdBuff
            .bindPipeline(relu6Pipeline)
            .bindDescSets({ relu6DescSet })
            .setPushConstants(0, sizeof(N), &N)
            .dispatch(N)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};

// Pointwise Conv + BatchNorm (no activation) - for projection layer
class PwConvBnNode : public Node
{
    uint32_t C_in, C_out;
    float eps;
    ComputePipeline pwconvPipeline;
    ComputePipeline bnPipeline;
    DescriptorSet pwconvDescSet;
    DescriptorSet bnDescSet;
public:
    PwConvBnNode(uint32_t inChannels, uint32_t outChannels, float epsilon = 1e-5f)
        : C_in(inChannels), C_out(outChannels), eps(epsilon)
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        addSlot("pw_out", NodeSlot::internal);
        addSlot("pw_weight", NodeSlot::input);
        addSlot("bn_gamma", NodeSlot::input);
        addSlot("bn_beta", NodeSlot::input);
        addSlot("bn_mean", NodeSlot::input);
        addSlot("bn_var", NodeSlot::input);
        pwconvPipeline = gDevice.createComputePipeline({ pwconv_srcCode });
        bnPipeline = gDevice.createComputePipeline({ batchnorm_srcCode });
        pwconvDescSet = pwconvPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        bnDescSet = bnPipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        const auto& inShape = (*this)["in0"].shape();
        _ASSERT(inShape.size() == 3);
        _ASSERT(inShape[2] == C_in);
        (*this)["pw_out"] = Tensor(inShape[0], inShape[1], C_out);
        (*this)["out0"] = Tensor(inShape[0], inShape[1], C_out);
    }
    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        uint32_t H = inShape[0], W = inShape[1];
        // Pointwise Conv
        pwconvDescSet.write({
            (*this)["pw_out"].buffer(),
            (*this)["in0"].buffer(),
            (*this)["pw_weight"].buffer(),
            });
        uint32_t pwConstants[] = { H, W, C_in, C_out };
        cmdBuff
            .bindPipeline(pwconvPipeline)
            .bindDescSets({ pwconvDescSet })
            .setPushConstants(0, sizeof(pwConstants), pwConstants)
            .dispatch(H, W, C_out)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["pw_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
        // BatchNorm
        bnDescSet.write({
            (*this)["out0"].buffer(),
            (*this)["pw_out"].buffer(),
            (*this)["bn_gamma"].buffer(),
            (*this)["bn_beta"].buffer(),
            (*this)["bn_mean"].buffer(),
            (*this)["bn_var"].buffer(),
            });
        struct { int HW, C; float eps; } bnConstants = { (int)(H * W), (int)C_out, eps };
        cmdBuff
            .bindPipeline(bnPipeline)
            .bindDescSets({ bnDescSet })
            .setPushConstants(0, sizeof(bnConstants), &bnConstants)
            .dispatch(H * W * C_out)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};

// Pointwise Conv + BatchNorm + ReLU6 - for expansion layer
class PwConvBnRelu6Node : public Node
{
    uint32_t C_in, C_out;
    float eps;
    ComputePipeline pwconvPipeline;
    ComputePipeline bnPipeline;
    ComputePipeline relu6Pipeline;
    DescriptorSet pwconvDescSet;
    DescriptorSet bnDescSet;
    DescriptorSet relu6DescSet;
public:
    PwConvBnRelu6Node(uint32_t inChannels, uint32_t outChannels, float epsilon = 1e-5f)
        : C_in(inChannels), C_out(outChannels), eps(epsilon)
    {
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        addSlot("pw_out", NodeSlot::internal);
        addSlot("bn_out", NodeSlot::internal);
        addSlot("pw_weight", NodeSlot::input);
        addSlot("bn_gamma", NodeSlot::input);
        addSlot("bn_beta", NodeSlot::input);
        addSlot("bn_mean", NodeSlot::input);
        addSlot("bn_var", NodeSlot::input);
        pwconvPipeline = gDevice.createComputePipeline({ pwconv_srcCode });
        bnPipeline = gDevice.createComputePipeline({ batchnorm_srcCode });
        relu6Pipeline = gDevice.createComputePipeline({ relu6_srcCode });
        pwconvDescSet = pwconvPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        bnDescSet = bnPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        relu6DescSet = relu6Pipeline.descSetLayout(0).newDescSet(gDestSetPool);
    }
    void prepare() override
    {
        const auto& inShape = (*this)["in0"].shape();
        _ASSERT(inShape.size() == 3);
        _ASSERT(inShape[2] == C_in);
        (*this)["pw_out"] = Tensor(inShape[0], inShape[1], C_out);
        (*this)["bn_out"] = Tensor(inShape[0], inShape[1], C_out);
        (*this)["out0"] = Tensor(inShape[0], inShape[1], C_out);
    }
    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        uint32_t H = inShape[0], W = inShape[1];
        // Pointwise Conv
        pwconvDescSet.write({
            (*this)["pw_out"].buffer(),
            (*this)["in0"].buffer(),
            (*this)["pw_weight"].buffer(),
            });
        uint32_t pwConstants[] = { H, W, C_in, C_out };
        cmdBuff
            .bindPipeline(pwconvPipeline)
            .bindDescSets({ pwconvDescSet })
            .setPushConstants(0, sizeof(pwConstants), pwConstants)
            .dispatch(H, W, C_out)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["pw_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
        // BatchNorm
        bnDescSet.write({
            (*this)["bn_out"].buffer(),
            (*this)["pw_out"].buffer(),
            (*this)["bn_gamma"].buffer(),
            (*this)["bn_beta"].buffer(),
            (*this)["bn_mean"].buffer(),
            (*this)["bn_var"].buffer(),
            });
        struct { int HW, C; float eps; } bnConstants = { (int)(H * W), (int)C_out, eps };
        cmdBuff
            .bindPipeline(bnPipeline)
            .bindDescSets({ bnDescSet })
            .setPushConstants(0, sizeof(bnConstants), &bnConstants)
            .dispatch(H * W * C_out)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["bn_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
        // ReLU6
        int N = H * W * C_out;
        relu6DescSet.write({
            (*this)["out0"].buffer(),
            (*this)["bn_out"].buffer(),
            });
        cmdBuff
            .bindPipeline(relu6Pipeline)
            .bindDescSets({ relu6DescSet })
            .setPushConstants(0, sizeof(N), &N)
            .dispatch(N)
            .barrier(
                (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["out0"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ)
            );
    }
};

// Inverted Residual Block
class InvertedResidualBlock : public Node
{
    uint32_t C_in, C_out, expandRatio, stride;
    uint32_t hiddenDim;
    bool useResidual;
    float eps;
    // Pipelines
    ComputePipeline pwconvPipeline;
    ComputePipeline dwconvPipeline;
    ComputePipeline bnPipeline;
    ComputePipeline relu6Pipeline;
    ComputePipeline addPipeline;
    // Descriptor sets for each stage
    DescriptorSet expandPwDescSet;
    DescriptorSet expandBnDescSet;
    DescriptorSet expandRelu6DescSet;
    DescriptorSet dwDescSet;
    DescriptorSet dwBnDescSet;
    DescriptorSet dwRelu6DescSet;
    DescriptorSet projPwDescSet;
    DescriptorSet projBnDescSet;
    DescriptorSet addDescSet;
public:
    InvertedResidualBlock(uint32_t inChannels, uint32_t outChannels,
        uint32_t expandRatio = 6, uint32_t stride = 1,
        float epsilon = 1e-5f)
        : C_in(inChannels), C_out(outChannels), expandRatio(expandRatio),
        stride(stride), eps(epsilon)
    {
        hiddenDim = C_in * expandRatio;
        useResidual = (stride == 1 && C_in == C_out);
        // Input/Output slots
        addSlot("in0", NodeSlot::input);
        addSlot("out0", NodeSlot::output);
        // Internal tensors
        if (expandRatio != 1) {
            addSlot("expand_pw_out", NodeSlot::internal);
            addSlot("expand_bn_out", NodeSlot::internal);
            addSlot("expand_relu6_out", NodeSlot::internal);
        }
        addSlot("dw_out", NodeSlot::internal);
        addSlot("dw_bn_out", NodeSlot::internal);
        addSlot("dw_relu6_out", NodeSlot::internal);
        addSlot("proj_pw_out", NodeSlot::internal);
        addSlot("proj_bn_out", NodeSlot::internal);
        // Weight slots - Expansion layer (only if expand ratio > 1)
        if (expandRatio != 1) {
            addSlot("expand_pw_weight", NodeSlot::input);
            addSlot("expand_bn_gamma", NodeSlot::input);
            addSlot("expand_bn_beta", NodeSlot::input);
            addSlot("expand_bn_mean", NodeSlot::input);
            addSlot("expand_bn_var", NodeSlot::input);
        }
        // Weight slots - Depthwise layer
        addSlot("dw_weight", NodeSlot::input);
        addSlot("dw_bn_gamma", NodeSlot::input);
        addSlot("dw_bn_beta", NodeSlot::input);
        addSlot("dw_bn_mean", NodeSlot::input);
        addSlot("dw_bn_var", NodeSlot::input);
        // Weight slots - Projection layer
        addSlot("proj_pw_weight", NodeSlot::input);
        addSlot("proj_bn_gamma", NodeSlot::input);
        addSlot("proj_bn_beta", NodeSlot::input);
        addSlot("proj_bn_mean", NodeSlot::input);
        addSlot("proj_bn_var", NodeSlot::input);
        // Create pipelines
        pwconvPipeline = gDevice.createComputePipeline({ pwconv_srcCode });
        dwconvPipeline = gDevice.createComputePipeline({ dwconv_srcCode });
        bnPipeline = gDevice.createComputePipeline({ batchnorm_srcCode });
        relu6Pipeline = gDevice.createComputePipeline({ relu6_srcCode });
        addPipeline = gDevice.createComputePipeline({ add_srcCode });
        // Create descriptor sets
        if (expandRatio != 1) {
            expandPwDescSet = pwconvPipeline.descSetLayout(0).newDescSet(gDestSetPool);
            expandBnDescSet = bnPipeline.descSetLayout(0).newDescSet(gDestSetPool);
            expandRelu6DescSet = relu6Pipeline.descSetLayout(0).newDescSet(gDestSetPool);
        }
        dwDescSet = dwconvPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        dwBnDescSet = bnPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        dwRelu6DescSet = relu6Pipeline.descSetLayout(0).newDescSet(gDestSetPool);
        projPwDescSet = pwconvPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        projBnDescSet = bnPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        if (useResidual) {
            addDescSet = addPipeline.descSetLayout(0).newDescSet(gDestSetPool);
        }
    }
    void prepare() override
    {
        const auto& inShape = (*this)["in0"].shape();
        _ASSERT(inShape.size() == 3);
        _ASSERT(inShape[2] == C_in);
        uint32_t H_in = inShape[0], W_in = inShape[1];
        uint32_t H_out = (H_in + 2 * 1 - 3) / stride + 1;  // K=3, pad=1
        uint32_t W_out = (W_in + 2 * 1 - 3) / stride + 1;
        if (expandRatio != 1) {
            (*this)["expand_pw_out"] = Tensor(H_in, W_in, hiddenDim);
            (*this)["expand_bn_out"] = Tensor(H_in, W_in, hiddenDim);
            (*this)["expand_relu6_out"] = Tensor(H_in, W_in, hiddenDim);
        }
        (*this)["dw_out"] = Tensor(H_out, W_out, hiddenDim);
        (*this)["dw_bn_out"] = Tensor(H_out, W_out, hiddenDim);
        (*this)["dw_relu6_out"] = Tensor(H_out, W_out, hiddenDim);
        (*this)["proj_pw_out"] = Tensor(H_out, W_out, C_out);
        (*this)["proj_bn_out"] = Tensor(H_out, W_out, C_out);
        (*this)["out0"] = Tensor(H_out, W_out, C_out);
    }
    void run(CommandBuffer cmdBuff) override
    {
        const auto& inShape = (*this)["in0"].shape();
        uint32_t H_in = inShape[0], W_in = inShape[1];
        uint32_t H_out = (*this)["dw_out"].shape()[0];
        uint32_t W_out = (*this)["dw_out"].shape()[1];
        Buffer currentInput = (*this)["in0"].buffer();
        uint32_t currentH = H_in, currentW = W_in, currentC = C_in;
        // ========== Expansion Layer (if t > 1) ==========
        if (expandRatio != 1) {
            // Pointwise Conv: C_in -> hiddenDim
            expandPwDescSet.write({
                (*this)["expand_pw_out"].buffer(),
                currentInput,
                (*this)["expand_pw_weight"].buffer(),
                });
            uint32_t pwConstants[] = { H_in, W_in, C_in, hiddenDim };
            cmdBuff
                .bindPipeline(pwconvPipeline)
                .bindDescSets({ expandPwDescSet })
                .setPushConstants(0, sizeof(pwConstants), pwConstants)
                .dispatch(H_in, W_in, hiddenDim)
                .barrier((PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                    / (*this)["expand_pw_out"].buffer()
                    / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
            // BatchNorm
            expandBnDescSet.write({
                (*this)["expand_bn_out"].buffer(),
                (*this)["expand_pw_out"].buffer(),
                (*this)["expand_bn_gamma"].buffer(),
                (*this)["expand_bn_beta"].buffer(),
                (*this)["expand_bn_mean"].buffer(),
                (*this)["expand_bn_var"].buffer(),
                });
            struct { int HW, C; float eps; } bnConstants = { (int)(H_in * W_in), (int)hiddenDim, eps };
            cmdBuff
                .bindPipeline(bnPipeline)
                .bindDescSets({ expandBnDescSet })
                .setPushConstants(0, sizeof(bnConstants), &bnConstants)
                .dispatch(H_in * W_in * hiddenDim)
                .barrier((PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                    / (*this)["expand_bn_out"].buffer()
                    / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
            // ReLU6
            int N = H_in * W_in * hiddenDim;
            expandRelu6DescSet.write({
                (*this)["expand_relu6_out"].buffer(),
                (*this)["expand_bn_out"].buffer(),
                });
            cmdBuff
                .bindPipeline(relu6Pipeline)
                .bindDescSets({ expandRelu6DescSet })
                .setPushConstants(0, sizeof(N), &N)
                .dispatch(N)
                .barrier((PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                    / (*this)["expand_relu6_out"].buffer()
                    / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
            currentInput = (*this)["expand_relu6_out"].buffer();
            currentC = hiddenDim;
        }
        // ========== Depthwise Layer ==========
        // Depthwise Conv
        dwDescSet.write({
            (*this)["dw_out"].buffer(),
            currentInput,
            (*this)["dw_weight"].buffer(),
            });
        struct {
            int H_in, W_in, C;
            int H_out, W_out;
            int K, stride, pad;
        } dwConstants = {
            (int)currentH, (int)currentW, (int)hiddenDim,
            (int)H_out, (int)W_out,
            3, (int)stride, 1
        };
        // If expansion was done, input dims changed
        if (expandRatio != 1) {
            dwConstants.H_in = H_in;
            dwConstants.W_in = W_in;
        }
        cmdBuff
            .bindPipeline(dwconvPipeline)
            .bindDescSets({ dwDescSet })
            .setPushConstants(0, sizeof(dwConstants), &dwConstants)
            .dispatch(H_out, W_out, hiddenDim)
            .barrier((PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["dw_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
        // BatchNorm
        dwBnDescSet.write({
            (*this)["dw_bn_out"].buffer(),
            (*this)["dw_out"].buffer(),
            (*this)["dw_bn_gamma"].buffer(),
            (*this)["dw_bn_beta"].buffer(),
            (*this)["dw_bn_mean"].buffer(),
            (*this)["dw_bn_var"].buffer(),
            });
        struct { int HW, C; float eps; } dwBnConstants = { (int)(H_out * W_out), (int)hiddenDim, eps };
        cmdBuff
            .bindPipeline(bnPipeline)
            .bindDescSets({ dwBnDescSet })
            .setPushConstants(0, sizeof(dwBnConstants), &dwBnConstants)
            .dispatch(H_out * W_out * hiddenDim)
            .barrier((PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["dw_bn_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
        // ReLU6
        int dwN = H_out * W_out * hiddenDim;
        dwRelu6DescSet.write({
            (*this)["dw_relu6_out"].buffer(),
            (*this)["dw_bn_out"].buffer(),
            });
        cmdBuff
            .bindPipeline(relu6Pipeline)
            .bindDescSets({ dwRelu6DescSet })
            .setPushConstants(0, sizeof(dwN), &dwN)
            .dispatch(dwN)
            .barrier((PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["dw_relu6_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
        // ========== Projection Layer ==========
        // Pointwise Conv: hiddenDim -> C_out
        projPwDescSet.write({
            (*this)["proj_pw_out"].buffer(),
            (*this)["dw_relu6_out"].buffer(),
            (*this)["proj_pw_weight"].buffer(),
            });
        uint32_t projPwConstants[] = { H_out, W_out, hiddenDim, C_out };
        cmdBuff
            .bindPipeline(pwconvPipeline)
            .bindDescSets({ projPwDescSet })
            .setPushConstants(0, sizeof(projPwConstants), projPwConstants)
            .dispatch(H_out, W_out, C_out)
            .barrier((PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["proj_pw_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
        // BatchNorm (no activation after projection!)
        projBnDescSet.write({
            (*this)["proj_bn_out"].buffer(),
            (*this)["proj_pw_out"].buffer(),
            (*this)["proj_bn_gamma"].buffer(),
            (*this)["proj_bn_beta"].buffer(),
            (*this)["proj_bn_mean"].buffer(),
            (*this)["proj_bn_var"].buffer(),
            });
        struct { int HW, C; float eps; } projBnConstants = { (int)(H_out * W_out), (int)C_out, eps };
        cmdBuff
            .bindPipeline(bnPipeline)
            .bindDescSets({ projBnDescSet })
            .setPushConstants(0, sizeof(projBnConstants), &projBnConstants)
            .dispatch(H_out * W_out * C_out)
            .barrier((PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                / (*this)["proj_bn_out"].buffer()
                / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
        // ========== Residual Add (if applicable) ==========
        if (useResidual) {
            int addN = H_out * W_out * C_out;
            addDescSet.write({
                (*this)["out0"].buffer(),
                (*this)["in0"].buffer(),
                (*this)["proj_bn_out"].buffer(),
                });
            cmdBuff
                .bindPipeline(addPipeline)
                .bindDescSets({ addDescSet })
                .setPushConstants(0, sizeof(addN), &addN)
                .dispatch(addN)
                .barrier((PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_WRITE)
                    / (*this)["out0"].buffer()
                    / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
        }
        else {
            // No residual path: copy projection output forward
            cmdBuff
                .copyBuffer((*this)["out0"].buffer(), (*this)["proj_bn_out"].buffer())
                .barrier((PIPELINE_STAGE::TRANSFER, ACCESS::TRANSFER_WRITE)
                    / (*this)["out0"].buffer()
                    / (PIPELINE_STAGE::COMPUTE_SHADER, ACCESS::SHADER_READ));
        }
    }
};


#endif // NEURAL_NODES_H