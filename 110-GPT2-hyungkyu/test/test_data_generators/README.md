# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±ê¸°

ë”¥ëŸ¬ë‹ ë ˆì´ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê³µí†µ ë°ì´í„° ìƒì„± í”„ë ˆì„ì›Œí¬

## ğŸ“ í´ë” êµ¬ì¡°

```
test_data_generators/
â”œâ”€â”€ json_exporter.py              # JSON ë‚´ë³´ë‚´ê¸° ìœ í‹¸ë¦¬í‹° (ê³µí†µ)
â”œâ”€â”€ <model_name>/                 # ëª¨ë¸ë³„ ìƒì„±ê¸° í´ë”
â”‚   â”œâ”€â”€ layers.py                 # ë ˆì´ì–´ êµ¬í˜„
â”‚   â”œâ”€â”€ generate_*_test_cpu.py    # CPU ë²„ì „ ìƒì„±ê¸°
â”‚   â”œâ”€â”€ generate_*_test_gpu.py    # GPU ë²„ì „ ìƒì„±ê¸°
â”‚   â””â”€â”€ generate_all_tests_*.py   # ì „ì²´ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ ...
```

## ğŸ¯ ì„¤ê³„ ì² í•™

ì´ í”„ë ˆì„ì›Œí¬ëŠ” **ëª¨ë¸ ë…ë¦½ì **ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤:
- ìƒˆë¡œìš´ ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±ê¸°ë¥¼ ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥
- ê³µí†µ ìœ í‹¸ë¦¬í‹°(`json_exporter.py`) ì¬ì‚¬ìš©
- ì¼ê´€ëœ JSON í˜•ì‹ìœ¼ë¡œ C++ í…ŒìŠ¤íŠ¸ì™€ ì—°ë™

## ğŸš€ ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ ìƒì„±ê¸° ì¶”ê°€ ë°©ë²•

### 1ë‹¨ê³„: ëª¨ë¸ í´ë” ìƒì„±

```bash
mkdir test_data_generators/<model_name>
```

### 2ë‹¨ê³„: ë ˆì´ì–´ êµ¬í˜„ ì‘ì„±

`<model_name>/layers.py` íŒŒì¼ì„ ì‘ì„±í•©ë‹ˆë‹¤:

```python
"""
<Model Name> ë ˆì´ì–´ êµ¬í˜„
ì°¸ì¡° êµ¬í˜„ ë˜ëŠ” ê³µì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜
"""
import torch
import torch.nn as nn

class YourLayer(nn.Module):
    def __init__(self, ...):
        super().__init__()
        # ë ˆì´ì–´ ì´ˆê¸°í™”

    def forward(self, x):
        # Forward pass êµ¬í˜„
        return output
```

### 3ë‹¨ê³„: ìƒì„±ê¸° ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

`generate_<layer>_test_gpu.py` í…œí”Œë¦¿:

```python
"""
<Layer> í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (GPU ë²„ì „)
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), '..'))

import torch
from layers import YourLayer  # ë ˆì´ì–´ import
from json_exporter import export_test_data, set_seed

# CUDA í™•ì¸
if not torch.cuda.is_available():
    print("ERROR: CUDA not available")
    sys.exit(1)

# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
set_seed(42)

# í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„±
input_data = torch.randn(batch, seq_len, d_model, dtype=torch.float32)

# ë ˆì´ì–´ ìƒì„± ë° ì´ˆê¸°í™”
layer = YourLayer(...)

# GPUë¡œ ì´ë™
layer = layer.cuda()
input_gpu = input_data.cuda()

# Forward pass
layer.eval()
with torch.no_grad():
    output_gpu = layer(input_gpu)

# CPUë¡œ ì´ë™í•˜ì—¬ export
output_data = output_gpu.cpu()

# JSONìœ¼ë¡œ ì €ì¥
export_test_data(
    output_path="../../assets/test_data/<layer>_test.json",
    input_data=input_data,
    output_data=output_data,
    parameters={
        "weight": layer.weight.cpu(),
        "bias": layer.bias.cpu()
    }  # íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ” ê²½ìš°
)

print(f"\n<Layer> test data generated with PyTorch GPU!")
```

### 4ë‹¨ê³„: CPU ë²„ì „ ì‘ì„±

GPU ë²„ì „ê³¼ ë™ì¼í•˜ë˜, `.cuda()` í˜¸ì¶œë§Œ ì œê±°:

```python
# GPU ëŒ€ì‹  CPUì—ì„œ ì‹¤í–‰
output_cpu = layer(input_data)

export_test_data(
    output_path="../../assets/test_data/<layer>_test.json",
    input_data=input_data,
    output_data=output_cpu,
    parameters={...}
)
```

### 5ë‹¨ê³„: ì „ì²´ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

`generate_all_tests_gpu.py`:

```python
"""
ëª¨ë“  í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¼ê´„ ìƒì„± (GPU)
"""
import subprocess
import sys
import os

generators = [
    "generate_layer1_test_gpu.py",
    "generate_layer2_test_gpu.py",
    # ... ì¶”ê°€
]

for i, generator in enumerate(generators, 1):
    print(f"[{i}/{len(generators)}] Running {generator}...")
    result = subprocess.run([sys.executable, generator], ...)
    # ì—ëŸ¬ ì²˜ë¦¬
```

## ğŸ”§ json_exporter.py ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©

```python
from json_exporter import export_test_data, set_seed

# 1. ì‹œë“œ ì„¤ì • (ì¬í˜„ì„±)
set_seed(42)

# 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
input_data = torch.randn(2, 4, 768)
output_data = layer(input_data)

# 3. JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
export_test_data(
    output_path="../../assets/test_data/my_layer_test.json",
    input_data=input_data,
    output_data=output_data,
    parameters=None  # íŒŒë¼ë¯¸í„°ê°€ ì—†ëŠ” ë ˆì´ì–´
)
```

### íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ” ë ˆì´ì–´

```python
export_test_data(
    output_path="../../assets/test_data/linear_test.json",
    input_data=input_data,
    output_data=output_data,
    parameters={
        "weight": layer.weight.cpu(),
        "bias": layer.bias.cpu()
    }
)
```

### ì§€ì› í˜•ì‹

- âœ… PyTorch tensor (CPU/GPU)
- âœ… NumPy array
- âœ… ìë™ Python list ë³€í™˜

## ğŸ“ íŒŒì¼ ë„¤ì´ë° ê·œì¹™

| ìš©ë„ | íŒŒì¼ëª… | ì„¤ëª… |
|------|--------|------|
| ë ˆì´ì–´ êµ¬í˜„ | `layers.py` | ëª¨ë¸ì˜ ë ˆì´ì–´ êµ¬í˜„ ëª¨ìŒ |
| GPU ìƒì„±ê¸° | `generate_<layer>_test_gpu.py` | GPU ê¸°ë°˜ ë°ì´í„° ìƒì„± |
| CPU ìƒì„±ê¸° | `generate_<layer>_test_cpu.py` | CPU ê¸°ë°˜ ë°ì´í„° ìƒì„± |
| ì „ì²´ ìƒì„± (GPU) | `generate_all_tests_gpu.py` | ëª¨ë“  GPU í…ŒìŠ¤íŠ¸ ìƒì„± |
| ì „ì²´ ìƒì„± (CPU) | `generate_all_tests_cpu.py` | ëª¨ë“  CPU í…ŒìŠ¤íŠ¸ ìƒì„± |

## ğŸ“Š ìƒì„±ë˜ëŠ” JSON í˜•ì‹

```json
{
  "input": [[[1.0, 2.0, ...]]],
  "output": [[[3.0, 4.0, ...]]],
  "parameters": {
    "weight": [[...]],
    "bias": [...]
  }
}
```

**í•„ìˆ˜ í•„ë“œ:**
- `input`: ì…ë ¥ í…ì„œ (ì¤‘ì²© ë¦¬ìŠ¤íŠ¸)
- `output`: ê¸°ëŒ€ ì¶œë ¥ í…ì„œ (ì¤‘ì²© ë¦¬ìŠ¤íŠ¸)

**ì„ íƒ í•„ë“œ:**
- `parameters`: ë ˆì´ì–´ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

## ğŸ¯ GPU vs CPU ë²„ì „

### GPU ë²„ì „ (ê¶Œì¥)
- **ìš©ë„**: í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸, Vulkan ë¹„êµ
- **ì¥ì **: GPU êµ¬í˜„ê³¼ ì§ì ‘ ë¹„êµ ê°€ëŠ¥
- **ìš”êµ¬ì‚¬í•­**: CUDA ì§€ì› GPU

### CPU ë²„ì „
- **ìš©ë„**: ê°œë°œ, ë””ë²„ê¹…, CI/CD
- **ì¥ì **: GPU ì—†ì´ë„ ì‹¤í–‰ ê°€ëŠ¥
- **ë‹¨ì **: GPU ê²°ê³¼ì™€ ì•½ê°„ì˜ ìˆ˜ì¹˜ ì°¨ì´

---

## ğŸ“š ì˜ˆì œ: GPT-2 ëª¨ë¸

í˜„ì¬ êµ¬í˜„ëœ GPT-2 ì˜ˆì œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”:

### í´ë” êµ¬ì¡°

```
test_data_generators/
â”œâ”€â”€ json_exporter.py
â””â”€â”€ torch/                        # GPT-2 ì˜ˆì œ
    â”œâ”€â”€ torch_layers.py           # GPT-2 ë ˆì´ì–´ (LLM-from-Scratch ê¸°ë°˜)
    â”œâ”€â”€ generate_gelu_test_gpu.py
    â”œâ”€â”€ generate_linear_test_gpu.py
    â”œâ”€â”€ generate_layernorm_test_gpu.py
    â”œâ”€â”€ generate_add_test_gpu.py
    â”œâ”€â”€ generate_attention_test_gpu.py
    â”œâ”€â”€ generate_feedforward_test_gpu.py
    â”œâ”€â”€ generate_transformer_test_gpu.py
    â”œâ”€â”€ generate_all_tests_gpu.py
    â””â”€â”€ ... (CPU ë²„ì „ë“¤)
```

### ì‚¬ìš© ì˜ˆì‹œ

```bash
# GPT-2 í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
cd test_data_generators/torch
C:\Users\USER\.conda\envs\torch\python.exe generate_all_tests_gpu.py
```

### êµ¬í˜„ëœ ë ˆì´ì–´

| ë ˆì´ì–´ | íŒŒì¼ëª… | ì„¤ëª… |
|--------|--------|------|
| GELU | `gelu_test.json` | GELU í™œì„±í™” í•¨ìˆ˜ |
| Linear | `linear_test.json` | ì„ í˜• ë³€í™˜ |
| LayerNorm | `layernorm_test.json` | ë ˆì´ì–´ ì •ê·œí™” |
| Add | `add_test.json` | ì”ì°¨ ì—°ê²° |
| MultiHeadAttention | `attention_test.json` | ë©€í‹°í—¤ë“œ ì…€í”„ ì–´í…ì…˜ |
| FeedForward | `feedforward_test.json` | MLP |
| TransformerBlock | `transformer_test.json` | ì „ì²´ íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡ |

### ë ˆì´ì–´ êµ¬í˜„ ì˜ˆì‹œ

`torch/torch_layers.py`ì—ì„œ ë°œì·Œ:

```python
class GELU(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x):
        return 0.5 * x * (1 + torch.tanh(
            torch.sqrt(torch.tensor(2.0 / torch.pi)) *
            (x + 0.044715 * torch.pow(x, 3))
        ))
```

### ìƒì„±ê¸° ì˜ˆì‹œ

`torch/generate_gelu_test_gpu.py`ì—ì„œ ë°œì·Œ:

```python
import torch
from torch_layers import GELU
from json_exporter import export_test_data, set_seed

set_seed(42)

input_data = torch.randn(2, 3, 8, dtype=torch.float32)
gelu = GELU().cuda()
output_gpu = gelu(input_data.cuda())

export_test_data(
    output_path="../../../assets/test_data/gelu_test.json",
    input_data=input_data,
    output_data=output_gpu.cpu()
)
```

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- C++ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬: `../README.md`
- ë¹„êµ ìŠ¤í¬ë¦½íŠ¸: `../../utils/final_comparison.py`
- GPT-2 ë ˆì´ì–´ êµ¬í˜„: `torch/torch_layers.py`

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€ ì‹œ:

- [ ] ëª¨ë¸ í´ë” ìƒì„±
- [ ] `layers.py` ì‘ì„±
- [ ] ê° ë ˆì´ì–´ë³„ GPU ìƒì„±ê¸° ì‘ì„±
- [ ] ê° ë ˆì´ì–´ë³„ CPU ìƒì„±ê¸° ì‘ì„±
- [ ] `generate_all_tests_gpu.py` ì‘ì„±
- [ ] `generate_all_tests_cpu.py` ì‘ì„±
- [ ] JSON íŒŒì¼ ìƒì„± í™•ì¸
- [ ] C++ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±
- [ ] ê²€ì¦ ë° ë¹„êµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
